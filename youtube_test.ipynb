{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googleapiclient.discovery\n",
    "import pymongo\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import streamlit as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_service_name = \"youtube\"\n",
    "api_version = \"v3\"\n",
    "youtube = googleapiclient.discovery.build(api_service_name, api_version, developerKey=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Channel Data\n",
    "def get_channel_data(ch_id):\n",
    "  c=[]\n",
    "  channel_request = youtube.channels().list(\n",
    "          part=\"snippet,contentDetails,statistics\",\n",
    "          id=ch_id\n",
    "      )\n",
    "  channel_response = channel_request.execute()\n",
    "  for i in channel_response['items']:\n",
    "    channel_data={\n",
    "        \"Channel_name\":i['snippet']['title'],\n",
    "        \"Channel_ID\":i['id'],\n",
    "        \"Channel_Subscriber\":i['statistics']['subscriberCount'],\n",
    "        \"Total_view\":i['statistics']['viewCount'],\n",
    "        \"Total_videos\":i['statistics']['videoCount'],\n",
    "        \"Channel_description\":i['snippet']['description'],\n",
    "        \"Playlist_Id\":i['contentDetails']['relatedPlaylists']['uploads']\n",
    "    }\n",
    "    c.append(channel_data)\n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get video_Id\n",
    "def get_video_id(ch_id):\n",
    "  v=[]\n",
    "  playlistID_request = youtube.channels().list(\n",
    "          part='contentDetails',\n",
    "          id=ch_id\n",
    "      )\n",
    "  playlistID_response=playlistID_request.execute()\n",
    "  playlist_id = playlistID_response['items'][0]['contentDetails']['relatedPlaylists']['uploads']\n",
    "  #print(playlist_id)\n",
    "  next_page_Token=None\n",
    "  while True:\n",
    "    videoID_request = youtube.playlistItems().list(\n",
    "         part='snippet',\n",
    "         playlistId=playlist_id,\n",
    "         maxResults=50,\n",
    "         pageToken=next_page_Token\n",
    "        )\n",
    "    videoID_response=videoID_request.execute()   \n",
    "    for j in range(len(videoID_response['items'])):\n",
    "      v_id=videoID_response['items'][j]['snippet']['resourceId']['videoId']\n",
    "      v.append(v_id)\n",
    "    next_page_Token=videoID_response.get('nextPageToken')\n",
    "    if next_page_Token is None:\n",
    "      break\n",
    "  return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video_Details:\n",
    "def get_video_data(vid):\n",
    "  vd=[]\n",
    "  for i in vid:\n",
    "    VideoData_request = youtube.videos().list(\n",
    "            part=\"snippet,contentDetails,statistics\",\n",
    "            id=i\n",
    "        )\n",
    "    VideoData_response = VideoData_request.execute()\n",
    "    for l in VideoData_response['items']:\n",
    "      video_data={\n",
    "          \"Channel_name\":l['snippet']['channelTitle'],\n",
    "          \"Channel_ID\":l['snippet']['channelId'],\n",
    "          \"Video_ID\":l['id'],\n",
    "          \"Title\":l['snippet']['title'],\n",
    "          \"Tags\":l['snippet'].get('tags'),\n",
    "          \"Thumbnails\":l['snippet']['thumbnails']['default']['url'],\n",
    "          \"Description\":l['snippet'].get('description'),\n",
    "          \"Published_Date\":l['snippet']['publishedAt'],\n",
    "          \"Duration\":l['contentDetails']['duration'],\n",
    "          \"Video_Views\":l['statistics'].get('viewCount'),\n",
    "          \"video_likes\":l['statistics'].get('likeCount'),\n",
    "          \"video_dislikes\":l['statistics'].get('dislikeCount'),\n",
    "          \"Video_Comments\":l['statistics'].get('commentCount'),\n",
    "          \"Favourite_count\":l['statistics']['favoriteCount'],\n",
    "          \"Definition\":l['contentDetails']['definition'],\n",
    "          \"Caption_Status\":l['contentDetails']['caption']\n",
    "      }\n",
    "      vd.append(video_data)\n",
    "  return vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get Comment_Info\n",
    "def get_comment_data(vid_id):\n",
    "  comment=[]\n",
    "  try:\n",
    "    for n in vid_id:\n",
    "      comment_request = youtube.commentThreads().list(\n",
    "                part=\"snippet,replies\",\n",
    "                videoId=n,\n",
    "                maxResults=50\n",
    "            )\n",
    "      comment_response = comment_request.execute()\n",
    "      for m in comment_response['items']:\n",
    "        comment_data={\n",
    "            \"comment_id\":m['id'],\n",
    "            \"video_id\":m['snippet']['videoId'],\n",
    "            \"comment_text\":m['snippet']['topLevelComment']['snippet']['textDisplay'],\n",
    "            \"comment_author\":m['snippet']['topLevelComment']['snippet']['authorDisplayName'],\n",
    "            \"comment_published_date\":m['snippet']['topLevelComment']['snippet']['publishedAt'] }\n",
    "        comment.append(comment_data)\n",
    "  except:\n",
    "    pass\n",
    "  return comment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get playlist_data\n",
    "def get_playlist_data(c_id):\n",
    "  next_Page_Token=None\n",
    "  playlist=[]\n",
    "  Playlist_request = youtube.playlists().list(\n",
    "          part=\"snippet,contentDetails\",\n",
    "          channelId=c_id,\n",
    "          maxResults=25,\n",
    "          pageToken=next_Page_Token\n",
    "      )\n",
    "  Playlist_response = Playlist_request.execute()\n",
    "  for p in Playlist_response['items']:\n",
    "    playlist_data={\n",
    "        \"Playlist_id\":p['id'],\n",
    "        \"Title\":p['snippet']['title'],\n",
    "        \"Channel_ID\":p['snippet']['channelId'],\n",
    "        \"Channel_name\":p['snippet']['channelTitle'],\n",
    "        \"Published_At\":p['snippet']['publishedAt'],\n",
    "        \"Video_count\":p['contentDetails']['itemCount']\n",
    "    }\n",
    "    playlist.append(playlist_data)\n",
    "  next_Page_Token=Playlist_response.get('nextPagetoken')\n",
    "  return playlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inserting data into MongoDB\n",
    "#Create Connection:\n",
    "conn=pymongo.MongoClient(\"mongodb://Srivaish:<password>@ac-9gjuw97-shard-00-00.yumx3ub.mongodb.net:27017,ac-9gjuw97-shard-00-01.yumx3ub.mongodb.net:27017,ac-9gjuw97-shard-00-02.yumx3ub.mongodb.net:27017/?ssl=true&replicaSet=atlas-rl70ym-shard-0&authSource=admin&retryWrites=true&w=majority&appName=Cluster0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Database\n",
    "Youtube_DB=conn['Youtube_Database']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Collection and Document\n",
    "def channel_detail(channel_id):\n",
    "    ch_data=get_channel_data(channel_id)\n",
    "    video_id=get_video_id(channel_id)\n",
    "    video_info=get_video_data(video_id)\n",
    "    playlist_info=get_playlist_data(channel_id)\n",
    "    c_data=get_comment_data(video_id)\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    col1.insert_one({'Channel_Information':ch_data,'Playlist_Information':playlist_info,\n",
    "                      'Video_Information':video_info,'Comment_Information':c_data})  \n",
    "    return \"Data has been Succesfully Uploaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Channel_Table in SQL\n",
    "def channel_table():\n",
    "    #importing\n",
    "    import psycopg2\n",
    "\n",
    "    # Establish a connection to your MySQL database\n",
    "    mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"root\",\n",
    "        database=\"youtube_data\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor object\n",
    "    mycursor = mydb.cursor()\n",
    "    drop_query='''drop table if exists channels'''\n",
    "    mycursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        # Define the CREATE TABLE query\n",
    "        create_query = '''\n",
    "            CREATE TABLE IF NOT EXISTS channels (\n",
    "                channel_name VARCHAR(100),\n",
    "                channel_ID VARCHAR(80) PRIMARY KEY,\n",
    "                total_view BIGINT,\n",
    "                total_subscribers BIGINT,\n",
    "                total_videos INT,\n",
    "                channel_description TEXT,\n",
    "                playlist_id VARCHAR(80)\n",
    "            )\n",
    "        '''\n",
    "\n",
    "        # Execute the query\n",
    "        mycursor.execute(create_query)\n",
    "\n",
    "        # Commit the changes\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        print(\"Table already exist\")\n",
    "    \n",
    "\n",
    "   #Extracting data from MongoDB\n",
    "    ch_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for ch_d in col1.find({},{\"_id\":0,\"Channel_Information\":1}):\n",
    "        for i in  range(len(ch_d['Channel_Information'])):\n",
    "            ch_list.append(ch_d['Channel_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df=pd.DataFrame(ch_list)\n",
    "    #Mapping with postgeral\n",
    "    for i,row in df.iterrows():\n",
    "        #print(i,row)\n",
    "        insert_query='''insert into channels( channel_name,\n",
    "                                            channel_ID,\n",
    "                                            total_view,\n",
    "                                            total_subscribers,\n",
    "                                            total_videos,\n",
    "                                            channel_description,\n",
    "                                            playlist_id)\n",
    "                                            values(%s,%s,%s,%s,%s,%s,%s)'''\n",
    "        values=(row['Channel_name'],\n",
    "                row['Channel_ID'],\n",
    "                row['Channel_Subscriber'],\n",
    "                row['Total_view'],\n",
    "                row['Total_videos'],\n",
    "                row['Channel_description'],\n",
    "                row['Playlist_Id'])\n",
    "    # Connect to your database and execute the query\n",
    "        try:\n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "            print(\"Record inserted successfully!\")\n",
    "        except:\n",
    "            print(\"Record already inserted\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playlist Table in SQL\n",
    "def playlist_table():\n",
    "    #importing\n",
    "    import pandas\n",
    "    import psycopg2\n",
    "\n",
    "    # Establish a connection to your MySQL database\n",
    "    mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"root\",\n",
    "        database=\"youtube_data\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor object\n",
    "    mycursor = mydb.cursor()\n",
    "    drop_query='''drop table if exists playlists'''\n",
    "    mycursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        # Define the CREATE TABLE query\n",
    "        create_query = '''\n",
    "            CREATE TABLE IF NOT EXISTS playlists (Playlist_id varchar(100) primary key,\n",
    "                                                Title  varchar(100),\n",
    "                                                Channel_ID varchar(100), \n",
    "                                                Channel_name varchar(100),\n",
    "                                                Published_At timestamp,\n",
    "                                                Video_count int)\n",
    "        '''\n",
    "\n",
    "        # Execute the query\n",
    "        mycursor.execute(create_query)\n",
    "\n",
    "        # Commit the changes\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        print(\"Table already exist\")\n",
    "\n",
    "\n",
    "    #Extracting data from MongoDB\n",
    "    pl_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for pl_d in col1.find({},{\"_id\":0,\"Playlist_Information\":1}):\n",
    "        for i in range(len(pl_d['Playlist_Information'])):\n",
    "            pl_list.append(pl_d['Playlist_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df1=pd.DataFrame(pl_list)\n",
    "\n",
    "\n",
    "    #Mapping with postgeral\n",
    "    for i,row in df1.iterrows():\n",
    "        #print(i,row)\n",
    "        insert_query='''insert into playlists(Playlist_id,\n",
    "                                            Title,\n",
    "                                            Channel_ID,\n",
    "                                            Channel_name,\n",
    "                                            Published_At,\n",
    "                                            Video_count\n",
    "                                            )\n",
    "                                            values(%s,%s,%s,%s,%s,%s)'''\n",
    "        values=(row['Playlist_id'],\n",
    "                row['Title'],\n",
    "                row['Channel_ID'],\n",
    "                row['Channel_name'],\n",
    "                row['Published_At'],\n",
    "                row['Video_count'])\n",
    "        \n",
    "        # Connect to your database and execute the query\n",
    "        try:\n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "            print(\"Playlist_Record inserted successfully!\")\n",
    "        except:\n",
    "            print(\"Playlist_Record already inserted\")\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Video Table\n",
    "def video_table():\n",
    "    # Establish a connection to your MySQL database\n",
    "    mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"root\",\n",
    "        database=\"youtube_data\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor object\n",
    "    mycursor = mydb.cursor()\n",
    "    drop_query='''drop table if exists videos'''\n",
    "    mycursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        # Define the CREATE TABLE query\n",
    "        create_query = '''\n",
    "            CREATE TABLE IF NOT EXISTS videos (Channel_name varchar(100),\n",
    "                                                Channel_ID varchar(100),\n",
    "                                                Video_ID varchar(100) primary key,\n",
    "                                                Title varchar(150),\n",
    "                                                Tags text,\n",
    "                                                Thumbnails varchar(200),\n",
    "                                                Description text,\n",
    "                                                Published_Date timestamp,\n",
    "                                                Duration interval,\n",
    "                                                Video_Views bigint,\n",
    "                                                video_likes bigint,\n",
    "                                                video_dislikes bigint,\n",
    "                                                Video_Comments int,\n",
    "                                                Favourite_count int,\n",
    "                                                Definition varchar(100),\n",
    "                                                Caption_Status varchar(100))\n",
    "        '''\n",
    "\n",
    "        # Execute the query\n",
    "        mycursor.execute(create_query)\n",
    "\n",
    "        # Commit the changes\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        print(\"Table already exist\")\n",
    "\n",
    "        \n",
    "    #Extracting data from MongoDB\n",
    "    vi_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for vi_d in col1.find({},{\"_id\":0,\"Video_Information\":1}):\n",
    "        for i in range(len(vi_d['Video_Information'])):\n",
    "            vi_list.append(vi_d['Video_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df2=pd.DataFrame(vi_list)\n",
    "\n",
    "\n",
    "    #Mapping with postgeral\n",
    "    for i,row in df2.iterrows():\n",
    "        #print(i,row)\n",
    "        insert_query='''insert into videos (Channel_name,\n",
    "                                            Channel_ID,\n",
    "                                            Video_ID,\n",
    "                                            Title,\n",
    "                                            Tags,\n",
    "                                            Thumbnails,\n",
    "                                            Description,\n",
    "                                            Published_Date,\n",
    "                                            Duration,\n",
    "                                            Video_Views,\n",
    "                                            video_likes ,\n",
    "                                            video_dislikes,\n",
    "                                            Video_Comments,\n",
    "                                            Favourite_count,\n",
    "                                            Definition,\n",
    "                                            Caption_Status   \n",
    "                                            )\n",
    "                                            values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'''\n",
    "    \n",
    "        values=(row['Channel_name'],\n",
    "                row['Channel_ID'],\n",
    "                row['Video_ID'],\n",
    "                row['Title'],\n",
    "                row['Tags'],\n",
    "                row['Thumbnails'],\n",
    "                row['Description'],\n",
    "                row['Published_Date'],\n",
    "                row['Duration'],\n",
    "                row['Video_Views'],\n",
    "                row['video_likes'],\n",
    "                row['video_dislikes'],\n",
    "                row['Video_Comments'],\n",
    "                row['Favourite_count'],\n",
    "                row['Definition'],\n",
    "                row['Caption_Status']\n",
    "                )\n",
    "        try:\n",
    "            #Connect to your database and execute the query\n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "            print(\"Video_Record inserted successfully!\")\n",
    "        except:\n",
    "            print(\"Video_record already inserted\")\n",
    "        \n",
    "\n",
    "video_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comment_table():\n",
    "    #Comment Table\n",
    "    # Establish a connection to your MySQL database\n",
    "    mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"root\",\n",
    "        database=\"youtube_data\"\n",
    "    )\n",
    "\n",
    "    # Create a cursor object\n",
    "    mycursor = mydb.cursor()\n",
    "    drop_query='''drop table if exists comments'''\n",
    "    mycursor.execute(drop_query)\n",
    "    mydb.commit()\n",
    "    try:\n",
    "        # Define the CREATE TABLE query\n",
    "        create_query = '''\n",
    "            CREATE TABLE IF NOT EXISTS comments(comment_id varchar(100) primary key,\n",
    "                                                video_id varchar(100),\n",
    "                                                comment_text text,\n",
    "                                                comment_author varchar(100) ,\n",
    "                                                comment_published_date timestamp\n",
    "                                                    \n",
    "            )\n",
    "        '''\n",
    "\n",
    "        # Execute the query\n",
    "        mycursor.execute(create_query)\n",
    "\n",
    "        # Commit the changes\n",
    "        mydb.commit()\n",
    "    except:\n",
    "        print(\"Table already exist\")\n",
    "\n",
    "\n",
    "    #Extracting data from MongoDB\n",
    "    com_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for com_d in col1.find({},{\"_id\":0,\"Comment_Information\":1}):\n",
    "        for i in range(len(com_d['Comment_Information'])):\n",
    "            com_list.append(com_d['Comment_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df3=pd.DataFrame(com_list)\n",
    "\n",
    "    #Mapping with postgeral\n",
    "    for i,row in df3.iterrows():\n",
    "        #print(i,row)\n",
    "        insert_query='''insert into comments(comment_id,\n",
    "                                            video_id,\n",
    "                                            comment_text,\n",
    "                                            comment_author,\n",
    "                                            comment_published_date\n",
    "                                            )\n",
    "                                            values(%s,%s,%s,%s,%s)'''\n",
    "        values=(row['comment_id'],\n",
    "                row['video_id'],\n",
    "                row['comment_text'],\n",
    "                row['comment_author'],\n",
    "                row['comment_published_date'])\n",
    "        \n",
    "        try:\n",
    "            mycursor.execute(insert_query,values)\n",
    "            mydb.commit()\n",
    "            print(\"Comment_Record inserted successfully!\")\n",
    "        except:\n",
    "            print(\"Comment_Record already inserted\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining function for all tables\n",
    "def tables():\n",
    "    channel_table()\n",
    "    playlist_table()\n",
    "    video_table()\n",
    "    comment_table()\n",
    "    return 'Table created and Migrated to SQL Database'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_channels_tables():\n",
    "    #Extracting channel data to streamlit\n",
    "    ch_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for ch_d in col1.find({},{\"_id\":0,\"Channel_Information\":1}):\n",
    "        for i in  range(len(ch_d['Channel_Information'])):\n",
    "                ch_list.append(ch_d['Channel_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df=st.dataframe(ch_list)\n",
    "\n",
    "def show_videos_tables():\n",
    "    #Extracting video data to streamlit\n",
    "    vi_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for vi_d in col1.find({},{\"_id\":0,\"Video_Information\":1}):\n",
    "        for i in range(len(vi_d['Video_Information'])):\n",
    "            vi_list.append(vi_d['Video_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df2=st.dataframe(vi_list)\n",
    "\n",
    "def show_playlists_tables():\n",
    "    #Extracting playlist data to streamlit\n",
    "    pl_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for pl_d in col1.find({},{\"_id\":0,\"Playlist_Information\":1}):\n",
    "        for i in range(len(pl_d['Playlist_Information'])):\n",
    "            pl_list.append(pl_d['Playlist_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df3=st.dataframe(pl_list)\n",
    "\n",
    "def show_comment_tables():\n",
    "    #Extracting comment data to streamlit\n",
    "    com_list=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"] \n",
    "    for com_d in col1.find({},{\"_id\":0,\"Comment_Information\":1}):\n",
    "        for i in range(len(com_d['Comment_Information'])):\n",
    "            com_list.append(com_d['Comment_Information'][i])\n",
    "    #Making the extracted data as dataframe\n",
    "    df3=st.dataframe(com_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Streamlit Part\n",
    "st.title(\":purple[Youtube Data Harvesting and warehousing]\")\n",
    "\n",
    "#Get_User_input\n",
    "channel_ID=st.text_input(\"Enter the Channel_ID:\")\n",
    "\n",
    "#Store to mongoDB database\n",
    "store_Data=st.button(\"Collect and store Data\")\n",
    "if store_Data:\n",
    "    ch_ids=[]\n",
    "    Youtube_DB=conn[\"Youtube_Database\"]\n",
    "    col1=Youtube_DB[\"Channel_Details\"]\n",
    "    for ch_data in col1.find({},{\"_id\":0,\"Channel_Information\":1}):\n",
    "        ch_ids.append(ch_data[\"Channel_Information\"]['Channel_ID'])\n",
    "    if channel_ID in ch_ids:\n",
    "        st.error(\"The given channel detail already exist in Database\")\n",
    "    else:\n",
    "        inserted=channel_detail(channel_ID)\n",
    "        st.success(\"Succesfully installed\")\n",
    "\n",
    "#Migrate to SQL\n",
    "SQL=st.button(\"Migrate to SQL\")\n",
    "if SQL:\n",
    "    Tables=tables()\n",
    "    st.success(Tables)\n",
    "\n",
    "#Displaying table for viewing\n",
    "show_tables=st.radio(\"Select the table for view\",(\"channels\",\"playlists\",\"videos\",\"comments\"))\n",
    "if show_tables == \"channels\":\n",
    "    show_channels_tables()\n",
    "elif show_tables == \"videos\":\n",
    "    show_videos_tables()\n",
    "elif show_tables == \"playlists\":\n",
    "    show_playlists_tables()\n",
    "elif show_tables == \"comments\":\n",
    "    show_comment_tables()\n",
    "\n",
    "#SQL_Query\n",
    "Questions=st.selectbox(\"Select your Question\",(\n",
    "                                              \"1.Name of all the videos and their corresponding channels\",\n",
    "                                              \"2.Channel that have most number of videos and the count of the videos\",\n",
    "                                              \"3.Top 10 viewed videos and their corresponding channels\",\n",
    "                                              \"4.Total number of comment on each video and their respective video name\",\n",
    "                                              \"5.Videos that have the highest number of likes and their corresponding channel name\",\n",
    "                                              \"6.Total number of likes and dislikes on each video and their corresponding video name\",\n",
    "                                              \"7.Total number of views for each channel and their respective channel name \",\n",
    "                                              \"8.Names of all the channel that have published video in the year 2022\",\n",
    "                                              \"9.Average duration of all videos in each channel and their corresponding channel name\",\n",
    "                                              \"10.Videos having highest number of comments and their corresponding channel name\"\n",
    "\n",
    "))\n",
    "\n",
    "mydb = psycopg2.connect(\n",
    "        host=\"localhost\",\n",
    "        user=\"postgres\",\n",
    "        password=\"root\",\n",
    "        database=\"youtube_data\"\n",
    "    )\n",
    "mycursor = mydb.cursor()\n",
    "\n",
    "if Questions==\"1.Name of all the videos and their corresponding channels\":\n",
    "    query1=''' select Title as Video_name,Channel_name from videos'''\n",
    "    mycursor.execute(query1)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df=pd.DataFrame(t1,columns=[\"Video_name\",\"Channel_name\"])\n",
    "    st.write(df)\n",
    "elif Questions==\"2.Channel that have most number of videos and the count of the videos\":\n",
    "    query2=''' select channel_name, total_videos from channels order by total_videos desc'''\n",
    "    mycursor.execute(query2)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df2=pd.DataFrame(t1,columns=[\"channel_name\",\"total_videos\"])\n",
    "    st.write(df2)\n",
    "elif Questions==\"3.Top 10 viewed videos and their corresponding channels\":\n",
    "    query3=''' select title,video_views from videos order by video_views desc limit 10'''\n",
    "    mycursor.execute(query3)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df3=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_views\"])\n",
    "    st.write(df3)\n",
    "elif Questions==\"4.Total number of comment on each video and their respective video name\":\n",
    "    query4=''' select title,video_comments from videos'''\n",
    "    mycursor.execute(query4)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df4=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_comments\"])\n",
    "    st.write(df4)\n",
    "elif  Questions==\"5.Videos that have the highest number of likes and their corresponding channel name\":\n",
    "    query5=''' select title,video_likes from videos where video_likes is not null order by video_likes desc'''\n",
    "    mycursor.execute(query5)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df5=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_likes\"])\n",
    "    st.write(df5) \n",
    "elif  Questions==\"6.Total number of likes and dislikes on each video and their corresponding video name\":\n",
    "    query6=''' select title,video_likes,video_dislikes from videos '''\n",
    "    mycursor.execute(query6)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df6=pd.DataFrame(t1,columns=[\"Video_title\",\"Video_likes\",\"Video_dislikes\"])\n",
    "    st.write(df6) \n",
    "elif Questions==\"7.Total number of views for each channel and their respective channel name \":\n",
    "    query7=''' select channel_name,total_view from channels '''\n",
    "    mycursor.execute(query7)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df7=pd.DataFrame(t1,columns=[\"Channel_name\",\"Total_view\"])\n",
    "    st.write(df7)  \n",
    "elif Questions==\"8.Names of all the channel that have published video in the year 2022\":\n",
    "    query8='''select title,channel_name,published_date from videos where extract(year from published_date)=2022'''\n",
    "    mycursor.execute(query8)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df8=pd.DataFrame(t1,columns=[\"Channel_name\",\"Year_Published\",\"Title\"])\n",
    "    st.write(df8)  \n",
    "elif Questions==\"9.Average duration of all videos in each channel and their corresponding channel name\":\n",
    "    query9='''select channel_name,AVG(duration) as avg_duration from videos group by channel_name'''\n",
    "    mycursor.execute(query9)\n",
    "    mydb.commit()\n",
    "    t1=mycursor.fetchall()\n",
    "    df9=pd.DataFrame(t1,columns=[\"Channel_name\",\"Avg_Duration\"])\n",
    "    t9=[]\n",
    "    for ind,row in df9.iterrows():\n",
    "        channel_title=row[\"Channel_name\"]\n",
    "        channel_avg_duration=row[\"Avg_Duration\"]\n",
    "        channel_avg_duration_str=str(channel_avg_duration)\n",
    "        t9.append({\"Channel_name\":channel_title,\"Channel_Avg_Duration\":channel_avg_duration_str})\n",
    "    df=pd.DataFrame(t9)\n",
    "    st.write(df)  \n",
    "elif  Questions==\"10.Videos having highest number of comments and their corresponding channel name\":\n",
    "    query10='''select title,channel_name,video_comments from videos where video_comments is not null order by video_comments  desc'''\n",
    "    mycursor.execute(query10)\n",
    "    mydb.commit()\n",
    "    t10=mycursor.fetchall()\n",
    "    df10=pd.DataFrame(t10,columns=[\"Channel_name\",\"Title\",\"video_comments\"])\n",
    "    st.write(df10)  \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "     \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
